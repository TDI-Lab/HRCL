### Dataset ###
[system]
# env_name-synthetic: gaussian, plansNum 16, dimension 100
# env_name-energy: energy, plansNum 10, dimension 144
#The folder name in the datasets path. Make sure it has no spaces, tabs or newlines (alphanum and underscore preferred)
dataset=gaussian

# any integer > 0
numAgents=40

# any integer > 0
numPlans=16

# exact dimensionality from the datasets
planDim=100

### Basic epos properties ###
# any integer > 0
numSimulations=1

# any integer > 0
numIterations=10

# any integer > 0
numChildren=2


### Multi-objective Cost Weights ###
# Number of supported objectives: 3
# Efficiency objective: 1-alpha-beta
# Fairness objective: alpha
# Discomfort objective: beta
# (1-alpha-beta)*inefficiency + alpha*unfairness + beta*discomfort
# "alpha,beta", e.g. "0.3,0.7" for alpha=0.3 and beta=0.7
# this needs to be removed actually
numberOfWeights = 2 
# Weights are in string format, separated by ","
weightsString = "0.0,0.0"

# Values: "same", "different".
behaviours=different
#filepath
agentsBehavioursPath=default

#sphinx
# Values: "VAR", "RSS", "XCORR", "RMSE"
# Goal signal is ignored in funcitons with only global response as input, e.g. var
globalCostFunction=RMSE

#vector target for global response same dimensionality as plan
#filepath
goalSignalPath=default

# Values: "STD", "UNIT-LENGTH", "MIN-MAX" ( only for RSS).
scaling="UNIT-LENGTH"

# Values: "INDEX", "DISC", "PREF"
localCostFunction="DISC"  

# Hard constraint for agents that violate in the first iteration
# Values: "SOFT", "PLAN", "COST", "PLAN_DOUBLE"
hardConstraint="SOFT"


### Shuffle seeds ###
# initial agent structure before reorganization occurs, any integer > 0
shuffle=0
isFirstRandom=0
# path to a file containing permutation of indices, need its structure: sphinx one column: integer index in each row
shuffle_file="permutation.csv" 

### Reorganization strategy ###
# possible values: periodically, convergence, globalCostReduction, never. never_strategy: never does reorganization
strategy=never
# any integer > 0, if "periodically" strategy is chosen
periodically.reorganizationPeriod=3
# any positive integer (>0), if "convergence" strategy is chosen, the iteration at which the selections will be memorized to be sued after the following reorganization
convergence.memorizationOffset=5
# double from [0, 1]
globalCost.reductionThreshold=0.5
# any integer. Keep the same seed to reproduce experiment results, what random permutations each strategy will explore, result reproducability
strategy.reorganizationSeed=0


### Loggers ###
logger.GlobalCostLogger = true
logger.LocalCostMultiObjectiveLogger = true
logger.TerminationLogger = false
logger.SelectedPlanLogger = true
logger.GlobalResponseVectorLogger = true
logger.PlanFrequencyLogger = false
logger.UnfairnessLogger = false
logger.GlobalComplexCostLogger = false
logger.WeightsLogger = false
logger.ReorganizationLogger = false
logger.VisualizerLogger = false

#Code related logger for debugging and checks
# please check here https://docs.oracle.com/javase/7/docs/api/java/util/logging/Level.html. For experiments "SEVERE" is preferred
logLevel="SEVERE"
